{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla M2050 (CNMeM is disabled, cuDNN not available)\n",
      "/mnt/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import FSRCNN_Theano\n",
    "import os\n",
    "import Fpreprocessing\n",
    "from scipy import ndimage,misc\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_prefix(image_name):\n",
    "    return image_name.split('_', 1)[0]\n",
    "def get_image_width(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[2]\n",
    "def get_image_height(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[3].split('.',1)[0]\n",
    "def create_image(image_folder, output_folder, output_type = 'YCbCr',upsampling_factor = 4):\n",
    "    reconstruct = dict()\n",
    "    for (dirpath,dirnames,filenames) in os.walk(image_folder):\n",
    "        print image_folder\n",
    "        filenames.sort()\n",
    "        #print(filenames)\n",
    "        \n",
    "        for counter,image_filename in enumerate(filenames):\n",
    "            print(get_image_prefix(image_filename))\n",
    "            print('\\n')\n",
    "            actual_image_name = get_image_prefix(image_filename)\n",
    "            if(actual_image_name not in reconstruct):\n",
    "                reconstruct[actual_image_name] = np.zeros((8,8,3))\n",
    "            if image_filename.split('.')[-1] == 'bmp' and image_filename[0] != '.':\n",
    "                if counter % 10 == 0:\n",
    "                    print \"processed:\" + str(counter)\n",
    "                image = misc.imread(os.path.join(image_folder,image_filename),flatten=False, mode = output_type)\n",
    "                #(width,height,channel_depth)\n",
    "                w = int(get_image_width(image_filename))\n",
    "                h = int(get_image_height(image_filename))\n",
    "                print (w,h)\n",
    "                print(image.shape)\n",
    "                print(reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:].shape)\n",
    "                reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:] = image\n",
    "                #misc.imshow(reconstruct[actual_image_name])\n",
    "                #img = Image.fromarray(data, 'RGB')\n",
    "                img = Image.fromarray(reconstruct[actual_image_name], 'RGB')\n",
    "                img.save('my.png')\n",
    "                img.show()\n",
    "                misc.imsave(os.path.join(actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "    #for key in recstruct:\n",
    "        #misc.imsave(os.path.join(output_folder,actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "#create_image('/home/ubuntu/Data/Validation_Subsamples_RGB_4','/home/ubuntu/Data/Reconstructed',output_type ='RGB',upsampling_factor = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Set5\n",
      "processed:0\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Validation_Subsamples_RGB_4/mapping.py')\n",
      "/home/ubuntu/Data/Training_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Training_Subsamples_RGB_4/mapping.py')\n"
     ]
    }
   ],
   "source": [
    "#Create Validation_Subsamples_RGB_4 and Validation_Subsamples_RGB_4_GT folders\n",
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set5',\n",
    "'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Training_Full',\n",
    "'/home/ubuntu/Data/Training_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Set14\n",
      "processed:0\n",
      "processed:10\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Test_Subsamples_RGB_4/mapping.py')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set14',\n",
    "'/home/ubuntu/Data/Test_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Training_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Training_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "done loading\n",
      "\n",
      "\n",
      "data_x: (22092, 3, 8, 8)\n",
      "data_y: (22092, 3, 33, 33)\n",
      "valid_x: (2488, 3, 8, 8)\n",
      "valid_y: (2488, 3, 33, 33)\n",
      "test_x: (14851, 3, 8, 8)\n",
      "test_y: (14851, 3, 33, 33)\n"
     ]
    }
   ],
   "source": [
    "import FSRCNN_Theano\n",
    "\n",
    "#load dataset\n",
    "\n",
    "#load training\n",
    "data_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4','data_x')\n",
    "data_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4_gt','data_y')\n",
    "valid_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4','data_x')\n",
    "valid_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt','data_y')\n",
    "test_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4','data_x')\n",
    "test_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4_gt','data_y')\n",
    "print \"done loading\\n\\n\"\n",
    "print \"data_x: \" + str(data_x.shape)\n",
    "print \"data_y: \" + str(data_y.shape)\n",
    "print \"valid_x: \" + str(valid_x.shape)\n",
    "print \"valid_y: \" + str(valid_y.shape)\n",
    "print \"test_x: \" + str(test_x.shape)\n",
    "print \"test_y: \" + str(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22092, 3, 8, 8)\n",
      "(22092, 3, 33, 33)\n",
      "(2488, 3, 8, 8)\n",
      "(14851, 3, 8, 8)\n",
      "(22092, 192)\n",
      "(22092, 3267)\n",
      "(2488, 192)\n",
      "(14851, 192)\n"
     ]
    }
   ],
   "source": [
    "#Bicubic interp to save computation during training\n",
    "upsampled_x = data_x #Fpreprocessing.upsample(data_x) #33,33,3 input images expected\n",
    "up_val_x = valid_x #Fpreprocessing.upsample(valid_x) #33,33,3 input images expected\n",
    "up_test_x = test_x #Fpreprocessing.upsample(test_x) #33,33,3 input images expected\n",
    "\n",
    "#Reshape for training,valid,test\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape\n",
    "\n",
    "upsampled_x = upsampled_x.reshape((22092,8*8*3))\n",
    "data_y = data_y.reshape((22092,33*33*3))\n",
    "up_val_x = up_val_x.reshape((2488,8*8*3))\n",
    "valid_y = valid_y.reshape((2488,33*33*3))\n",
    "up_test_x = up_test_x.reshape((14851,8*8*3))\n",
    "test_y = test_y.reshape((14851,33*33*3))\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.005******************************************\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (64, 3, 9, 9)\n",
      "image_shape...: (500, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (32, 64, 5, 5)\n",
      "image_shape...: (500, 64, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (3, 32, 9, 9)\n",
      "image_shape...: (500, 32, 16, 16)\n",
      "input shape....: Shape.0\n",
      "[<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>]\n",
      "epoch 1, minibatch 44/44, validation cost 17655.847656 mse/pixel: 22.989386 pnsr: 35.037273\n",
      "     epoch 1, minibatch 44/44, test cost of best model 17609.144531 perpixel mse 22.928572 and test pnsr 34.936455\n",
      "Optimization complete.\n",
      "Best validation pnsr of 17655.847656 obtained at iteration 44, with test cost 17609.144531 perpixel mse 22.928572 test pnsr 34.936455\n",
      "The training process for function train_FSRCNN2 ran for 0.46m\n"
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "#shared_y = T.cast(shared_y,'int32')\n",
    "\n",
    "batch_size = 500\n",
    "n_epochs = 1\n",
    "lrs = [0.005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano.train_FSRCNN2(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 288, '\\n')\n",
      "(19, 19, '\\n')\n",
      "(256, 256, '\\n')\n",
      "(16, 16, '\\n')\n",
      "(280, 280, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(344, 228, '\\n')\n",
      "(23, 14, '\\n')\n",
      "(480, 500, '\\n')\n",
      "(32, 34, '\\n')\n",
      "(576, 720, '\\n')\n",
      "(39, 50, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(361, 250, '\\n')\n",
      "(24, 16, '\\n')\n",
      "(276, 276, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(362, 500, '\\n')\n",
      "(24, 34, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 768, '\\n')\n",
      "(35, 53, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(656, 529, '\\n')\n",
      "(45, 36, '\\n')\n",
      "(391, 586, '\\n')\n",
      "(26, 40, '\\n')\n"
     ]
    }
   ],
   "source": [
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 16, 16))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=16,dataset='validate_new')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 16, 16))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=16,dataset='test_new')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test',place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "10 epochs takes 1.4m with batchsize=20 \n",
    "10 epochs takes .81m with batchsize=50\n",
    "10 epochs takes 1.3m with batchsize=10\n",
    "10 epochs takes .59m with batchsize=100 cost = 11404075.000000, mse/pixel = 8619.859375, pnsr = 8.786202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autosave 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.0005******************************************\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (64, 3, 9, 9)\n",
      "image_shape...: (25, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (32, 64, 5, 5)\n",
      "image_shape...: (25, 64, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (3, 32, 9, 9)\n",
      "image_shape...: (25, 32, 16, 16)\n",
      "input shape....: Shape.0\n",
      "[<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, vector)>]\n",
      "epoch 1, minibatch 883/883, validation cost 19055.087891 mse/pixel: 24.811314 pnsr: 35.352371\n",
      "     epoch 1, minibatch 883/883, test cost of best model 18935.554688 perpixel mse 24.655668 and test pnsr 34.929226\n",
      "epoch 2, minibatch 883/883, validation cost 18302.476562 mse/pixel: 23.831348 pnsr: 35.572918\n",
      "     epoch 2, minibatch 883/883, test cost of best model 17865.158203 perpixel mse 23.261923 and test pnsr 35.152218\n",
      "epoch 3, minibatch 883/883, validation cost 18127.328125 mse/pixel: 23.603289 pnsr: 35.638092\n",
      "new learning rate:\n",
      "CudaNdarray(0.000500000023749)\n",
      "     epoch 3, minibatch 883/883, test cost of best model 17679.095703 perpixel mse 23.019657 and test pnsr 35.204872\n",
      "epoch 4, minibatch 883/883, validation cost 18068.771484 mse/pixel: 23.527046 pnsr: 35.665874\n",
      "new learning rate:\n",
      "CudaNdarray(0.000497500004712)\n",
      "     epoch 4, minibatch 883/883, test cost of best model 17622.042969 perpixel mse 22.945372 and test pnsr 35.222431\n",
      "epoch 5, minibatch 883/883, validation cost 18041.091797 mse/pixel: 23.491003 pnsr: 35.680424\n",
      "     epoch 5, minibatch 883/883, test cost of best model 17605.554688 perpixel mse 22.923903 and test pnsr 35.226742\n",
      "epoch 6, minibatch 883/883, validation cost 18029.115234 mse/pixel: 23.475409 pnsr: 35.687279\n",
      "new learning rate:\n",
      "CudaNdarray(0.000495012500323)\n",
      "     epoch 6, minibatch 883/883, test cost of best model 17596.619141 perpixel mse 22.912264 and test pnsr 35.228851\n",
      "epoch 7, minibatch 883/883, validation cost 18022.337891 mse/pixel: 23.466583 pnsr: 35.691605\n",
      "new learning rate:\n",
      "CudaNdarray(0.000492537452374)\n",
      "     epoch 7, minibatch 883/883, test cost of best model 17588.591797 perpixel mse 22.901812 and test pnsr 35.230858\n",
      "epoch 8, minibatch 883/883, validation cost 18018.759766 mse/pixel: 23.461924 pnsr: 35.694321\n",
      "new learning rate:\n",
      "CudaNdarray(0.000490074744448)\n",
      "     epoch 8, minibatch 883/883, test cost of best model 17583.074219 perpixel mse 22.894627 and test pnsr 35.232376\n",
      "epoch 9, minibatch 883/883, validation cost 18016.517578 mse/pixel: 23.459007 pnsr: 35.696064\n",
      "new learning rate:\n",
      "CudaNdarray(0.000487624376547)\n",
      "     epoch 9, minibatch 883/883, test cost of best model 17579.878906 perpixel mse 22.890465 and test pnsr 35.233330\n",
      "epoch 10, minibatch 883/883, validation cost 18015.599609 mse/pixel: 23.457811 pnsr: 35.696686\n",
      "new learning rate:\n",
      "CudaNdarray(0.000485186261358)\n",
      "     epoch 10, minibatch 883/883, test cost of best model 17578.826172 perpixel mse 22.889097 and test pnsr 35.233673\n",
      "Optimization complete.\n",
      "Best validation pnsr of 18015.599609 obtained at iteration 8830, with test cost 17578.826172 perpixel mse 22.889097 test pnsr 35.233673\n",
      "The training process for function train_FSRCNN2 ran for 5.35m\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 288, '\\n')\n",
      "(19, 19, '\\n')\n",
      "(256, 256, '\\n')\n",
      "(16, 16, '\\n')\n",
      "(280, 280, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(344, 228, '\\n')\n",
      "(23, 14, '\\n')\n",
      "(480, 500, '\\n')\n",
      "(32, 34, '\\n')\n",
      "(576, 720, '\\n')\n",
      "(39, 50, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(361, 250, '\\n')\n",
      "(24, 16, '\\n')\n",
      "(276, 276, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(362, 500, '\\n')\n",
      "(24, 34, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 768, '\\n')\n",
      "(35, 53, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(656, 529, '\\n')\n",
      "(45, 36, '\\n')\n",
      "(391, 586, '\\n')\n",
      "(26, 40, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (17,17,3) (16,16,3) (17,17,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-278d95b274f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m      \u001b[0mreconstructed_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstucted_patches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mFSRCNN_Theano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrebuild_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstructed_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/home/ubuntu/Data/Validation_Subsamples_RGB_4/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validate_lr=5e4_model2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mreconstructed_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14851\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Theano.pyc\u001b[0m in \u001b[0;36mrebuild_images\u001b[1;34m(reconstructed_patches, subimages_folder, patch_dim, dataset, place)\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[0mplacements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw_beg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw_end\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_beg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh_end\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatch_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw_beg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw_end\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_beg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh_end\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;31m#average pixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (17,17,3) (16,16,3) (17,17,3) "
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "n_epochs = 10\n",
    "lrs = [.0005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano.train_FSRCNN2(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4)\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 16, 16))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=16,dataset='validate_lr=5e4_model2')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 16, 16))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=16,dataset='test_lr=5e4_model2')\n",
    "\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 16, 16))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=16,dataset='validate_lr=5e4_model2', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 16, 16))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=16,dataset='test_lr=5e4-model2',place=True)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
