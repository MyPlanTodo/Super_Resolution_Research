{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla M2050 (CNMeM is disabled, cuDNN not available)\n",
      "/mnt/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import FSRCNN_Theano, FSRCNN_Theano2\n",
    "import os\n",
    "import Fpreprocessing\n",
    "from scipy import ndimage,misc\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_prefix(image_name):\n",
    "    return image_name.split('_', 1)[0]\n",
    "def get_image_width(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[2]\n",
    "def get_image_height(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[3].split('.',1)[0]\n",
    "def create_image(image_folder, output_folder, output_type = 'YCbCr',upsampling_factor = 4):\n",
    "    reconstruct = dict()\n",
    "    for (dirpath,dirnames,filenames) in os.walk(image_folder):\n",
    "        print image_folder\n",
    "        filenames.sort()\n",
    "        #print(filenames)\n",
    "        \n",
    "        for counter,image_filename in enumerate(filenames):\n",
    "            print(get_image_prefix(image_filename))\n",
    "            print('\\n')\n",
    "            actual_image_name = get_image_prefix(image_filename)\n",
    "            if(actual_image_name not in reconstruct):\n",
    "                reconstruct[actual_image_name] = np.zeros((8,8,3))\n",
    "            if image_filename.split('.')[-1] == 'bmp' and image_filename[0] != '.':\n",
    "                if counter % 10 == 0:\n",
    "                    print \"processed:\" + str(counter)\n",
    "                image = misc.imread(os.path.join(image_folder,image_filename),flatten=False, mode = output_type)\n",
    "                #(width,height,channel_depth)\n",
    "                w = int(get_image_width(image_filename))\n",
    "                h = int(get_image_height(image_filename))\n",
    "                print (w,h)\n",
    "                print(image.shape)\n",
    "                print(reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:].shape)\n",
    "                reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:] = image\n",
    "                #misc.imshow(reconstruct[actual_image_name])\n",
    "                #img = Image.fromarray(data, 'RGB')\n",
    "                img = Image.fromarray(reconstruct[actual_image_name], 'RGB')\n",
    "                img.save('my.png')\n",
    "                img.show()\n",
    "                misc.imsave(os.path.join(actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "    #for key in recstruct:\n",
    "        #misc.imsave(os.path.join(output_folder,actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "#create_image('/home/ubuntu/Data/Validation_Subsamples_RGB_4','/home/ubuntu/Data/Reconstructed',output_type ='RGB',upsampling_factor = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Set5\n",
      "processed:0\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Validation_Subsamples_RGB_4/mapping.py')\n",
      "/home/ubuntu/Data/Training_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Training_Subsamples_RGB_4/mapping.py')\n"
     ]
    }
   ],
   "source": [
    "#Create Validation_Subsamples_RGB_4 and Validation_Subsamples_RGB_4_GT folders\n",
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set5',\n",
    "'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Training_Full',\n",
    "'/home/ubuntu/Data/Training_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Set14\n",
      "processed:0\n",
      "processed:10\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4/\n",
      "('\\n', '/home/ubuntu/Data/Test_Subsamples_RGB_4/mapping.py')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set14',\n",
    "'/home/ubuntu/Data/Test_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Training_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Training_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "done loading\n",
      "\n",
      "\n",
      "data_x: (22092, 3, 8, 8)\n",
      "data_y: (22092, 3, 33, 33)\n",
      "valid_x: (2488, 3, 8, 8)\n",
      "valid_y: (2488, 3, 33, 33)\n",
      "test_x: (14851, 3, 8, 8)\n",
      "test_y: (14851, 3, 33, 33)\n"
     ]
    }
   ],
   "source": [
    "import FSRCNN_Theano\n",
    "\n",
    "#load dataset\n",
    "\n",
    "#load training\n",
    "data_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4','data_x')\n",
    "data_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4_gt','data_y')\n",
    "valid_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4','data_x')\n",
    "valid_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt','data_y')\n",
    "test_x = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4','data_x')\n",
    "test_y = FSRCNN_Theano.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4_gt','data_y')\n",
    "print \"done loading\\n\\n\"\n",
    "print \"data_x: \" + str(data_x.shape)\n",
    "print \"data_y: \" + str(data_y.shape)\n",
    "print \"valid_x: \" + str(valid_x.shape)\n",
    "print \"valid_y: \" + str(valid_y.shape)\n",
    "print \"test_x: \" + str(test_x.shape)\n",
    "print \"test_y: \" + str(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22092, 3, 8, 8)\n",
      "(22092, 3, 33, 33)\n",
      "(2488, 3, 8, 8)\n",
      "(14851, 3, 8, 8)\n",
      "(22092, 192)\n",
      "(22092, 3267)\n",
      "(2488, 192)\n",
      "(14851, 192)\n"
     ]
    }
   ],
   "source": [
    "#Bicubic interp to save computation during training\n",
    "upsampled_x = data_x #Fpreprocessing.upsample(data_x) #33,33,3 input images expected\n",
    "up_val_x = valid_x #Fpreprocessing.upsample(valid_x) #33,33,3 input images expected\n",
    "up_test_x = test_x #Fpreprocessing.upsample(test_x) #33,33,3 input images expected\n",
    "\n",
    "#Reshape for training,valid,test\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape\n",
    "\n",
    "upsampled_x = upsampled_x.reshape((22092,8*8*3))\n",
    "data_y = data_y.reshape((22092,33*33*3))\n",
    "up_val_x = up_val_x.reshape((2488,8*8*3))\n",
    "valid_y = valid_y.reshape((2488,33*33*3))\n",
    "up_test_x = up_test_x.reshape((14851,8*8*3))\n",
    "test_y = test_y.reshape((14851,33*33*3))\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.05******************************************\n",
      "theano optimizer: fast_compile\n",
      "('batch size', 100)\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (56, 3, 5, 5)\n",
      "image_shape...: (100, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "conv1 done....\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (12, 56, 1, 1)\n",
      "image_shape...: (100, 56, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (12, 12, 3, 3)\n",
      "image_shape...: (100, 12, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (12, 12, 3, 3)\n",
      "image_shape...: (100, 12, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (12, 12, 3, 3)\n",
      "image_shape...: (100, 12, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (12, 12, 3, 3)\n",
      "image_shape...: (100, 12, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (56, 12, 1, 1)\n",
      "image_shape...: (100, 12, 8, 8)\n",
      "input shape....: Shape.0\n",
      "decon layer....\n",
      "\n",
      "filter_shape...: (3, 56, 10, 10)\n",
      "image_shape...: (100, 56, 8, 8)\n",
      "input shape....: Shape.0\n",
      "Shape.0\n",
      "('output len...', 17)\n",
      "epoch 1, minibatch 220/220, validation cost 15548603.000000 mse/pixel: 17933.798828 pnsr: 6.413752\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 1, minibatch 220/220, test cost of best model 15148912.000000 perpixel mse 17472.792969 and test pnsr 6.313978\n",
      "epoch 2, minibatch 220/220, validation cost 15476339.000000 mse/pixel: 17850.449219 pnsr: 6.435895\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 2, minibatch 220/220, test cost of best model 15072633.000000 perpixel mse 17384.814453 and test pnsr 6.338232\n",
      "epoch 3, minibatch 220/220, validation cost 15407500.000000 mse/pixel: 17771.050781 pnsr: 6.456503\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 3, minibatch 220/220, test cost of best model 14999720.000000 perpixel mse 17300.714844 and test pnsr 6.361200\n",
      "epoch 4, minibatch 220/220, validation cost 15342675.000000 mse/pixel: 17696.279297 pnsr: 6.475353\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 4, minibatch 220/220, test cost of best model 14930785.000000 perpixel mse 17221.207031 and test pnsr 6.382653\n",
      "epoch 5, minibatch 220/220, validation cost 15282352.000000 mse/pixel: 17626.703125 pnsr: 6.492269\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 5, minibatch 220/220, test cost of best model 14866346.000000 perpixel mse 17146.880859 and test pnsr 6.402399\n",
      "epoch 6, minibatch 220/220, validation cost 15226909.000000 mse/pixel: 17562.755859 pnsr: 6.507122\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 6, minibatch 220/220, test cost of best model 14806805.000000 perpixel mse 17078.207031 and test pnsr 6.420294\n",
      "epoch 7, minibatch 220/220, validation cost 15176608.000000 mse/pixel: 17504.740234 pnsr: 6.519845\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 7, minibatch 220/220, test cost of best model 14752455.000000 perpixel mse 17015.519531 and test pnsr 6.436244\n",
      "epoch 8, minibatch 220/220, validation cost 15131592.000000 mse/pixel: 17452.818359 pnsr: 6.530427\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 8, minibatch 220/220, test cost of best model 14703460.000000 perpixel mse 16959.009766 and test pnsr 6.450207\n",
      "epoch 9, minibatch 220/220, validation cost 15091885.000000 mse/pixel: 17407.017578 pnsr: 6.538913\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 9, minibatch 220/220, test cost of best model 14659878.000000 perpixel mse 16908.744141 and test pnsr 6.462190\n",
      "epoch 10, minibatch 220/220, validation cost 15057397.000000 mse/pixel: 17367.240234 pnsr: 6.545399\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 10, minibatch 220/220, test cost of best model 14621644.000000 perpixel mse 16864.642578 and test pnsr 6.472246\n",
      "epoch 11, minibatch 220/220, validation cost 15027939.000000 mse/pixel: 17333.263672 pnsr: 6.550032\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 11, minibatch 220/220, test cost of best model 14588598.000000 perpixel mse 16826.523438 and test pnsr 6.480473\n",
      "epoch 12, minibatch 220/220, validation cost 15003224.000000 mse/pixel: 17304.757812 pnsr: 6.553000\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 12, minibatch 220/220, test cost of best model 14560470.000000 perpixel mse 16794.085938 and test pnsr 6.487007\n",
      "epoch 13, minibatch 220/220, validation cost 14982893.000000 mse/pixel: 17281.306641 pnsr: 6.554521\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 13, minibatch 220/220, test cost of best model 14536936.000000 perpixel mse 16766.939453 and test pnsr 6.492015\n",
      "epoch 14, minibatch 220/220, validation cost 14966516.000000 mse/pixel: 17262.416016 pnsr: 6.554839\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 14, minibatch 220/220, test cost of best model 14517582.000000 perpixel mse 16744.615234 and test pnsr 6.495686\n",
      "epoch 15, minibatch 220/220, validation cost 14953624.000000 mse/pixel: 17247.546875 pnsr: 6.554205\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 15, minibatch 220/220, test cost of best model 14501958.000000 perpixel mse 16726.593750 and test pnsr 6.498222\n",
      "epoch 16, minibatch 220/220, validation cost 14943720.000000 mse/pixel: 17236.125000 pnsr: 6.552876\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 16, minibatch 220/220, test cost of best model 14489582.000000 perpixel mse 16712.322266 and test pnsr 6.499834\n",
      "epoch 17, minibatch 220/220, validation cost 14936305.000000 mse/pixel: 17227.572266 pnsr: 6.551092\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 17, minibatch 220/220, test cost of best model 14479971.000000 perpixel mse 16701.236328 and test pnsr 6.500727\n",
      "epoch 18, minibatch 220/220, validation cost 14930904.000000 mse/pixel: 17221.343750 pnsr: 6.549070\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 18, minibatch 220/220, test cost of best model 14472645.000000 perpixel mse 16692.787109 and test pnsr 6.501088\n",
      "epoch 19, minibatch 220/220, validation cost 14927075.000000 mse/pixel: 17216.925781 pnsr: 6.546993\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 19, minibatch 220/220, test cost of best model 14467164.000000 perpixel mse 16686.464844 and test pnsr 6.501088\n",
      "epoch 20, minibatch 220/220, validation cost 14924431.000000 mse/pixel: 17213.876953 pnsr: 6.545003\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 20, minibatch 220/220, test cost of best model 14463131.000000 perpixel mse 16681.814453 and test pnsr 6.500868\n",
      "epoch 21, minibatch 220/220, validation cost 14922649.000000 mse/pixel: 17211.822266 pnsr: 6.543199\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 21, minibatch 220/220, test cost of best model 14460207.000000 perpixel mse 16678.441406 and test pnsr 6.500534\n",
      "epoch 22, minibatch 220/220, validation cost 14921475.000000 mse/pixel: 17210.466797 pnsr: 6.541639\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 22, minibatch 220/220, test cost of best model 14458114.000000 perpixel mse 16676.025391 and test pnsr 6.500166\n",
      "epoch 23, minibatch 220/220, validation cost 14920712.000000 mse/pixel: 17209.587891 pnsr: 6.540344\n",
      "new learning rate:\n",
      "CudaNdarray(0.0500000007451)\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 23, minibatch 220/220, test cost of best model 14456628.000000 perpixel mse 16674.310547 and test pnsr 6.499816\n",
      "epoch 24, minibatch 220/220, validation cost 14920225.000000 mse/pixel: 17209.025391 pnsr: 6.539310\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 24, minibatch 220/220, test cost of best model 14455585.000000 perpixel mse 16673.107422 and test pnsr 6.499510\n",
      "epoch 25, minibatch 220/220, validation cost 14919913.000000 mse/pixel: 17208.666016 pnsr: 6.538509\n",
      "new learning rate:\n",
      "CudaNdarray(0.0497500002384)\n",
      "148\n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3, 17, 17)\n",
      "     epoch 25, minibatch 220/220, test cost of best model 14454855.000000 perpixel mse 16672.267578 and test pnsr 6.499259\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-41cac337505c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                              \u001b[0mshared_test_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshared_test_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                              n_epochs, batch_size,learning_rate,upsampling_factor=4)\n\u001b[0m",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Theano2.pyc\u001b[0m in \u001b[0;36mtrain_FSRCNN\u001b[1;34m(train_set_x, train_set_y, valid_set_x, valid_set_y, test_set_x, test_set_y, n_train_batches, n_valid_batches, n_test_batches, n_epochs, batch_size, lr, upsampling_factor)\u001b[0m\n\u001b[0;32m    193\u001b[0m     train_nn(train_model, validate_model, test_model,\n\u001b[0;32m    194\u001b[0m             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecay_learning_rate_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             verbose = False)\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Layers.pyc\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(train_model, validate_model, test_model, n_train_batches, n_valid_batches, n_test_batches, n_epochs, output_len, decay_learning_rate_function, verbose)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_train_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mminibatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;31m#cost_ij,mse_ij,pnsr_ij = train_model(minibatch_index,lr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[0mcost_ij\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse_ij\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpnsr_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 print('training @ iter = ' + str(iter) + \"\\tcost = \" + str(cost_ij) + \n",
      "\u001b[1;32m/mnt/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "#shared_y = T.cast(shared_y,'int32')\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 100\n",
    "lrs = [.05]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano2.train_FSRCNN(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_2')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_2')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_2', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_2',place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "10 epochs takes 1.4m with batchsize=20 \n",
    "10 epochs takes .81m with batchsize=50\n",
    "10 epochs takes 1.3m with batchsize=10\n",
    "10 epochs takes .59m with batchsize=100 cost = 11404075.000000, mse/pixel = 8619.859375, pnsr = 8.786202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
