{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla M2050 (CNMeM is disabled, cuDNN not available)\n",
      "/mnt/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import FSRCNN_Theano_Data\n",
    "import os\n",
    "import Fpreprocessing\n",
    "from scipy import ndimage,misc\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_prefix(image_name):\n",
    "    return image_name.split('_', 1)[0]\n",
    "def get_image_width(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[2]\n",
    "def get_image_height(image_name):\n",
    "    yo = image_name.split(\"_\")\n",
    "    return yo[3].split('.',1)[0]\n",
    "def create_image(image_folder, output_folder, output_type = 'YCbCr',upsampling_factor = 4):\n",
    "    reconstruct = dict()\n",
    "    for (dirpath,dirnames,filenames) in os.walk(image_folder):\n",
    "        print image_folder\n",
    "        filenames.sort()\n",
    "        #print(filenames)\n",
    "        \n",
    "        for counter,image_filename in enumerate(filenames):\n",
    "            print(get_image_prefix(image_filename))\n",
    "            print('\\n')\n",
    "            actual_image_name = get_image_prefix(image_filename)\n",
    "            if(actual_image_name not in reconstruct):\n",
    "                reconstruct[actual_image_name] = np.zeros((8,8,3))\n",
    "            if image_filename.split('.')[-1] == 'bmp' and image_filename[0] != '.':\n",
    "                if counter % 10 == 0:\n",
    "                    print \"processed:\" + str(counter)\n",
    "                image = misc.imread(os.path.join(image_folder,image_filename),flatten=False, mode = output_type)\n",
    "                #(width,height,channel_depth)\n",
    "                w = int(get_image_width(image_filename))\n",
    "                h = int(get_image_height(image_filename))\n",
    "                print (w,h)\n",
    "                print(image.shape)\n",
    "                print(reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:].shape)\n",
    "                reconstruct[actual_image_name][14*w:14*w+33,14*h:14*h+33,:] = image\n",
    "                #misc.imshow(reconstruct[actual_image_name])\n",
    "                #img = Image.fromarray(data, 'RGB')\n",
    "                img = Image.fromarray(reconstruct[actual_image_name], 'RGB')\n",
    "                img.save('my.png')\n",
    "                img.show()\n",
    "                misc.imsave(os.path.join(actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "    #for key in recstruct:\n",
    "        #misc.imsave(os.path.join(output_folder,actual_image_name+'.bmp'),reconstruct[actual_image_name])\n",
    "#create_image('/home/ubuntu/Data/Validation_Subsamples_RGB_4','/home/ubuntu/Data/Reconstructed',output_type ='RGB',upsampling_factor = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFpreprocessing.create_subimages('/home/ubuntu/Data/Set5',\\n'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',\\noutput_type ='RGB',upsampling_factor = 4)\\n\\nFpreprocessing.create_subimages('/home/ubuntu/Data/Training_Full',\\n'/home/ubuntu/Data/Training_Subsamples_RGB_4/',\\noutput_type ='RGB',upsampling_factor = 4)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Validation_Subsamples_RGB_4 and Validation_Subsamples_RGB_4_GT folders\n",
    "'''\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set5',\n",
    "'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Training_Full',\n",
    "'/home/ubuntu/Data/Training_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFpreprocessing.create_subimages('/home/ubuntu/Data/Set14',\\n'/home/ubuntu/Data/Test_Subsamples_RGB_4/',\\noutput_type ='RGB',upsampling_factor = 4)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fpreprocessing.create_subimages('/home/ubuntu/Data/Set14',\n",
    "'/home/ubuntu/Data/Test_Subsamples_RGB_4/',\n",
    "output_type ='RGB',upsampling_factor = 4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Data/Training_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Training_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4\n",
      "loading from npz\n",
      "/home/ubuntu/Data/Test_Subsamples_RGB_4_gt\n",
      "loading from npz\n",
      "done loading\n",
      "\n",
      "\n",
      "data_x: (22092, 3, 8, 8)\n",
      "data_y: (22092, 3, 33, 33)\n",
      "valid_x: (2488, 3, 8, 8)\n",
      "valid_y: (2488, 3, 33, 33)\n",
      "test_x: (14851, 3, 8, 8)\n",
      "test_y: (14851, 3, 33, 33)\n"
     ]
    }
   ],
   "source": [
    "import FSRCNN_Theano\n",
    "\n",
    "#load dataset\n",
    "\n",
    "#load training\n",
    "data_x = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4','data_x')\n",
    "data_y = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Training_Subsamples_RGB_4_gt','data_y')\n",
    "valid_x = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4','data_x')\n",
    "valid_y = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Validation_Subsamples_RGB_4_gt','data_y')\n",
    "test_x = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4','data_x')\n",
    "test_y = FSRCNN_Theano_Data.load_dataset('/home/ubuntu/Data/Test_Subsamples_RGB_4_gt','data_y')\n",
    "print \"done loading\\n\\n\"\n",
    "print \"data_x: \" + str(data_x.shape)\n",
    "print \"data_y: \" + str(data_y.shape)\n",
    "print \"valid_x: \" + str(valid_x.shape)\n",
    "print \"valid_y: \" + str(valid_y.shape)\n",
    "print \"test_x: \" + str(test_x.shape)\n",
    "print \"test_y: \" + str(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22092, 3, 8, 8)\n",
      "(22092, 3, 33, 33)\n",
      "(2488, 3, 8, 8)\n",
      "(14851, 3, 8, 8)\n",
      "(22092, 192)\n",
      "(22092, 3267)\n",
      "(2488, 192)\n",
      "(14851, 192)\n"
     ]
    }
   ],
   "source": [
    "#Bicubic interp to save computation during training\n",
    "upsampled_x = data_x #Fpreprocessing.upsample(data_x) #33,33,3 input images expected\n",
    "up_val_x = valid_x #Fpreprocessing.upsample(valid_x) #33,33,3 input images expected\n",
    "up_test_x = test_x #Fpreprocessing.upsample(test_x) #33,33,3 input images expected\n",
    "\n",
    "#Reshape for training,valid,test\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape\n",
    "\n",
    "upsampled_x = upsampled_x.reshape((22092,8*8*3))\n",
    "data_y = data_y.reshape((22092,33*33*3))\n",
    "up_val_x = up_val_x.reshape((2488,8*8*3))\n",
    "valid_y = valid_y.reshape((2488,33*33*3))\n",
    "up_test_x = up_test_x.reshape((14851,8*8*3))\n",
    "test_y = test_y.reshape((14851,33*33*3))\n",
    "\n",
    "print upsampled_x.shape\n",
    "print data_y.shape\n",
    "print up_val_x.shape\n",
    "print up_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "10 epochs takes 1.4m with batchsize=20 \n",
    "10 epochs takes .81m with batchsize=50\n",
    "10 epochs takes 1.3m with batchsize=10\n",
    "10 epochs takes .59m with batchsize=100 cost = 11404075.000000, mse/pixel = 8619.859375, pnsr = 8.786202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.0005******************************************\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (64, 3, 9, 9)\n",
      "image_shape...: (50, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (32, 64, 5, 5)\n",
      "image_shape...: (50, 64, 8, 8)\n",
      "input shape....: Shape.0\n",
      "decon layer....\n",
      "\n",
      "filter_shape...: (3, 32, 10, 10)\n",
      "image_shape...: (50, 32, 8, 8)\n",
      "input shape....: Shape.0\n",
      "epoch 1, minibatch 441/441, validation cost 3805.149170 mse/pixel: 4.388869 pnsr: 42.251648\n",
      "     epoch 1, minibatch 441/441, test cost of best model 4699.959473 perpixel mse 5.420945 and test pnsr 41.433060\n",
      "epoch 2, minibatch 441/441, validation cost 3571.634277 mse/pixel: 4.119532 pnsr: 42.539719\n",
      "new learning rate:\n",
      "CudaNdarray(0.000500000023749)\n",
      "     epoch 2, minibatch 441/441, test cost of best model 4568.111328 perpixel mse 5.268872 and test pnsr 41.603642\n",
      "epoch 3, minibatch 441/441, validation cost 3637.538818 mse/pixel: 4.195547 pnsr: 42.511391\n",
      "new learning rate:\n",
      "CudaNdarray(0.000497500004712)\n",
      "epoch 4, minibatch 441/441, validation cost 3396.573975 mse/pixel: 3.917617 pnsr: 42.831573\n",
      "new learning rate:\n",
      "CudaNdarray(0.000495012500323)\n",
      "     epoch 4, minibatch 441/441, test cost of best model 4121.602051 perpixel mse 4.753866 and test pnsr 42.002537\n",
      "epoch 5, minibatch 441/441, validation cost 2935.658203 mse/pixel: 3.385995 pnsr: 43.451172\n",
      "     epoch 5, minibatch 441/441, test cost of best model 3504.945312 perpixel mse 4.042613 and test pnsr 42.682892\n",
      "epoch 6, minibatch 441/441, validation cost 2441.106934 mse/pixel: 2.815579 pnsr: 44.234680\n",
      "new learning rate:\n",
      "CudaNdarray(0.000492537452374)\n",
      "     epoch 6, minibatch 441/441, test cost of best model 2825.089844 perpixel mse 3.258466 and test pnsr 43.593719\n",
      "epoch 7, minibatch 441/441, validation cost 2138.514893 mse/pixel: 2.466568 pnsr: 44.801819\n",
      "     epoch 7, minibatch 441/441, test cost of best model 2391.802490 perpixel mse 2.758711 and test pnsr 44.302841\n",
      "epoch 8, minibatch 441/441, validation cost 1816.523438 mse/pixel: 2.095183 pnsr: 45.492104\n",
      "new learning rate:\n",
      "CudaNdarray(0.000490074744448)\n",
      "     epoch 8, minibatch 441/441, test cost of best model 2006.997925 perpixel mse 2.314877 and test pnsr 45.068943\n",
      "epoch 9, minibatch 441/441, validation cost 1719.786499 mse/pixel: 1.983606 pnsr: 45.725800\n",
      "new learning rate:\n",
      "CudaNdarray(0.000487624376547)\n",
      "     epoch 9, minibatch 441/441, test cost of best model 1870.173828 perpixel mse 2.157063 and test pnsr 45.370136\n",
      "epoch 10, minibatch 441/441, validation cost 1516.320923 mse/pixel: 1.748928 pnsr: 46.255142\n",
      "new learning rate:\n",
      "CudaNdarray(0.000485186261358)\n",
      "     epoch 10, minibatch 441/441, test cost of best model 1684.255981 perpixel mse 1.942625 and test pnsr 45.858612\n",
      "epoch 11, minibatch 441/441, validation cost 1476.298096 mse/pixel: 1.702766 pnsr: 46.368603\n",
      "new learning rate:\n",
      "CudaNdarray(0.000482760340674)\n",
      "     epoch 11, minibatch 441/441, test cost of best model 1648.267334 perpixel mse 1.901116 and test pnsr 45.963539\n",
      "epoch 12, minibatch 441/441, validation cost 1352.670898 mse/pixel: 1.560174 pnsr: 46.736000\n",
      "new learning rate:\n",
      "CudaNdarray(0.000480346527183)\n",
      "     epoch 12, minibatch 441/441, test cost of best model 1513.196289 perpixel mse 1.745324 and test pnsr 46.344303\n",
      "epoch 13, minibatch 441/441, validation cost 1338.605347 mse/pixel: 1.543951 pnsr: 46.771519\n",
      "new learning rate:\n",
      "CudaNdarray(0.000477944791783)\n",
      "     epoch 13, minibatch 441/441, test cost of best model 1536.073608 perpixel mse 1.771711 and test pnsr 46.309887\n",
      "epoch 14, minibatch 441/441, validation cost 1275.427490 mse/pixel: 1.471081 pnsr: 46.968525\n",
      "     epoch 14, minibatch 441/441, test cost of best model 1475.302612 perpixel mse 1.701618 and test pnsr 46.499866\n",
      "epoch 15, minibatch 441/441, validation cost 1284.536377 mse/pixel: 1.481588 pnsr: 46.929771\n",
      "new learning rate:\n",
      "CudaNdarray(0.000475555076264)\n",
      "epoch 16, minibatch 441/441, validation cost 1138.661621 mse/pixel: 1.313335 pnsr: 47.454151\n",
      "new learning rate:\n",
      "CudaNdarray(0.000473177293316)\n",
      "     epoch 16, minibatch 441/441, test cost of best model 1296.243530 perpixel mse 1.495090 and test pnsr 47.057358\n",
      "epoch 17, minibatch 441/441, validation cost 1171.620117 mse/pixel: 1.351350 pnsr: 47.325211\n",
      "new learning rate:\n",
      "CudaNdarray(0.000470811413834)\n",
      "epoch 18, minibatch 441/441, validation cost 1190.600464 mse/pixel: 1.373242 pnsr: 47.247231\n",
      "new learning rate:\n",
      "CudaNdarray(0.000468457350507)\n",
      "epoch 19, minibatch 441/441, validation cost 1118.899658 mse/pixel: 1.290542 pnsr: 47.532181\n",
      "new learning rate:\n",
      "CudaNdarray(0.000466115074232)\n",
      "     epoch 19, minibatch 441/441, test cost of best model 1247.523804 perpixel mse 1.438897 and test pnsr 47.194386\n",
      "epoch 20, minibatch 441/441, validation cost 1172.850952 mse/pixel: 1.352769 pnsr: 47.319809\n",
      "new learning rate:\n",
      "CudaNdarray(0.000463784497697)\n",
      "epoch 21, minibatch 441/441, validation cost 1181.346802 mse/pixel: 1.362568 pnsr: 47.288929\n",
      "new learning rate:\n",
      "CudaNdarray(0.000461465591798)\n",
      "epoch 22, minibatch 441/441, validation cost 1044.582886 mse/pixel: 1.204825 pnsr: 47.850689\n",
      "new learning rate:\n",
      "CudaNdarray(0.000459158269223)\n",
      "     epoch 22, minibatch 441/441, test cost of best model 1117.328125 perpixel mse 1.288729 and test pnsr 47.691086\n",
      "epoch 23, minibatch 441/441, validation cost 1023.149475 mse/pixel: 1.180103 pnsr: 47.932899\n",
      "new learning rate:\n",
      "CudaNdarray(0.000456862471765)\n",
      "     epoch 23, minibatch 441/441, test cost of best model 1068.010620 perpixel mse 1.231846 and test pnsr 47.878735\n",
      "epoch 24, minibatch 441/441, validation cost 1106.612305 mse/pixel: 1.276369 pnsr: 47.580002\n",
      "new learning rate:\n",
      "CudaNdarray(0.00045457817032)\n",
      "epoch 25, minibatch 441/441, validation cost 1013.356995 mse/pixel: 1.168809 pnsr: 47.994026\n",
      "new learning rate:\n",
      "CudaNdarray(0.000452305277577)\n",
      "     epoch 25, minibatch 441/441, test cost of best model 1015.314819 perpixel mse 1.171067 and test pnsr 48.105614\n",
      "epoch 26, minibatch 441/441, validation cost 1071.595703 mse/pixel: 1.235981 pnsr: 47.744431\n",
      "new learning rate:\n",
      "CudaNdarray(0.000450043764431)\n",
      "epoch 27, minibatch 441/441, validation cost 990.555969 mse/pixel: 1.142510 pnsr: 48.105236\n",
      "new learning rate:\n",
      "CudaNdarray(0.000447793543572)\n",
      "     epoch 27, minibatch 441/441, test cost of best model 974.578613 perpixel mse 1.124081 and test pnsr 48.292030\n",
      "epoch 28, minibatch 441/441, validation cost 981.760742 mse/pixel: 1.132365 pnsr: 48.148582\n",
      "new learning rate:\n",
      "CudaNdarray(0.000445554585895)\n",
      "     epoch 28, minibatch 441/441, test cost of best model 951.900024 perpixel mse 1.097924 and test pnsr 48.408432\n",
      "epoch 29, minibatch 441/441, validation cost 1066.243164 mse/pixel: 1.229808 pnsr: 47.781658\n",
      "new learning rate:\n",
      "CudaNdarray(0.000443326804088)\n",
      "epoch 30, minibatch 441/441, validation cost 1009.348511 mse/pixel: 1.164185 pnsr: 48.028854\n",
      "new learning rate:\n",
      "CudaNdarray(0.000441110169049)\n",
      "epoch 31, minibatch 441/441, validation cost 1036.619385 mse/pixel: 1.195639 pnsr: 47.904514\n",
      "new learning rate:\n",
      "CudaNdarray(0.00043890462257)\n",
      "epoch 32, minibatch 441/441, validation cost 979.757874 mse/pixel: 1.130055 pnsr: 48.166229\n",
      "new learning rate:\n",
      "CudaNdarray(0.000436710106442)\n",
      "     epoch 32, minibatch 441/441, test cost of best model 954.486755 perpixel mse 1.100908 and test pnsr 48.359921\n",
      "epoch 33, minibatch 441/441, validation cost 918.280273 mse/pixel: 1.059147 pnsr: 48.493763\n",
      "new learning rate:\n",
      "CudaNdarray(0.000434526562458)\n",
      "     epoch 33, minibatch 441/441, test cost of best model 882.682556 perpixel mse 1.018088 and test pnsr 48.759365\n",
      "epoch 34, minibatch 441/441, validation cost 937.678833 mse/pixel: 1.081521 pnsr: 48.373230\n",
      "new learning rate:\n",
      "CudaNdarray(0.00043235393241)\n",
      "epoch 35, minibatch 441/441, validation cost 918.620789 mse/pixel: 1.059540 pnsr: 48.485271\n",
      "new learning rate:\n",
      "CudaNdarray(0.000430192158092)\n",
      "epoch 36, minibatch 441/441, validation cost 871.745239 mse/pixel: 1.005473 pnsr: 48.717087\n",
      "new learning rate:\n",
      "CudaNdarray(0.000428041210398)\n",
      "     epoch 36, minibatch 441/441, test cost of best model 831.478577 perpixel mse 0.959030 and test pnsr 49.012016\n",
      "epoch 37, minibatch 441/441, validation cost 938.634155 mse/pixel: 1.082623 pnsr: 48.382210\n",
      "new learning rate:\n",
      "CudaNdarray(0.000425901002018)\n",
      "epoch 38, minibatch 441/441, validation cost 886.468689 mse/pixel: 1.022455 pnsr: 48.647743\n",
      "new learning rate:\n",
      "CudaNdarray(0.000423771503847)\n",
      "epoch 39, minibatch 441/441, validation cost 917.849548 mse/pixel: 1.058650 pnsr: 48.483509\n",
      "new learning rate:\n",
      "CudaNdarray(0.000421652657678)\n",
      "epoch 40, minibatch 441/441, validation cost 874.653137 mse/pixel: 1.008827 pnsr: 48.715557\n",
      "new learning rate:\n",
      "CudaNdarray(0.000419544405304)\n",
      "epoch 41, minibatch 441/441, validation cost 959.910583 mse/pixel: 1.107163 pnsr: 48.294071\n",
      "new learning rate:\n",
      "CudaNdarray(0.000417446688516)\n",
      "epoch 42, minibatch 441/441, validation cost 846.779358 mse/pixel: 0.976677 pnsr: 48.880577\n",
      "new learning rate:\n",
      "CudaNdarray(0.000415359449107)\n",
      "     epoch 42, minibatch 441/441, test cost of best model 814.101868 perpixel mse 0.938987 and test pnsr 49.150208\n",
      "epoch 43, minibatch 441/441, validation cost 881.260864 mse/pixel: 1.016448 pnsr: 48.685905\n",
      "new learning rate:\n",
      "CudaNdarray(0.000413282657973)\n",
      "epoch 44, minibatch 441/441, validation cost 840.451599 mse/pixel: 0.969379 pnsr: 48.912304\n",
      "new learning rate:\n",
      "CudaNdarray(0.000411216256907)\n",
      "     epoch 44, minibatch 441/441, test cost of best model 813.559692 perpixel mse 0.938362 and test pnsr 49.150608\n",
      "epoch 45, minibatch 441/441, validation cost 815.618164 mse/pixel: 0.940736 pnsr: 49.030041\n",
      "new learning rate:\n",
      "CudaNdarray(0.000409160187701)\n",
      "     epoch 45, minibatch 441/441, test cost of best model 796.117737 perpixel mse 0.918244 and test pnsr 49.224525\n",
      "epoch 46, minibatch 441/441, validation cost 842.457458 mse/pixel: 0.971692 pnsr: 48.904591\n",
      "new learning rate:\n",
      "CudaNdarray(0.000407114392146)\n",
      "epoch 47, minibatch 441/441, validation cost 817.118713 mse/pixel: 0.942467 pnsr: 49.065186\n",
      "new learning rate:\n",
      "CudaNdarray(0.000405078812037)\n",
      "epoch 48, minibatch 441/441, validation cost 833.088257 mse/pixel: 0.960886 pnsr: 48.957142\n",
      "new learning rate:\n",
      "CudaNdarray(0.000403053418268)\n",
      "epoch 49, minibatch 441/441, validation cost 795.961670 mse/pixel: 0.918064 pnsr: 49.170959\n",
      "new learning rate:\n",
      "CudaNdarray(0.000401038152631)\n",
      "     epoch 49, minibatch 441/441, test cost of best model 792.571045 perpixel mse 0.914153 and test pnsr 49.298576\n",
      "epoch 50, minibatch 441/441, validation cost 847.702576 mse/pixel: 0.977742 pnsr: 48.865559\n",
      "new learning rate:\n",
      "CudaNdarray(0.000399032956921)\n",
      "epoch 51, minibatch 441/441, validation cost 835.657288 mse/pixel: 0.963849 pnsr: 48.947510\n",
      "new learning rate:\n",
      "CudaNdarray(0.000397037802031)\n",
      "epoch 52, minibatch 441/441, validation cost 828.798462 mse/pixel: 0.955938 pnsr: 48.988628\n",
      "new learning rate:\n",
      "CudaNdarray(0.000395052600652)\n",
      "epoch 53, minibatch 441/441, validation cost 795.244324 mse/pixel: 0.917237 pnsr: 49.159084\n",
      "new learning rate:\n",
      "CudaNdarray(0.000393077352783)\n",
      "     epoch 53, minibatch 441/441, test cost of best model 786.107483 perpixel mse 0.906698 and test pnsr 49.331184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.py:516: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b75d45ff2595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                              \u001b[0mshared_test_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshared_test_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                              n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0.15, rotate_p=0.15)\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mreconstructed_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_valid_batches\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_valid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Theano_Data.pyc\u001b[0m in \u001b[0;36mtrain_FSRCNN\u001b[1;34m(train_set_x, train_set_y, valid_set_x, valid_set_y, test_set_x, test_set_y, n_train_batches, n_valid_batches, n_test_batches, n_epochs, batch_size, lr, upsampling_factor, flip_p, rotate_p, translate_p, noise_p)\u001b[0m\n\u001b[0;32m    252\u001b[0m     train_nn_augmented(train_set_x, train_model, validate_model, test_model,\n\u001b[0;32m    253\u001b[0m             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecay_learning_rate_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m              batch_size = batch_size, flip_p = flip_p, rotate_p = rotate_p, translate_p = translate_p, noise_p = noise_p)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Layers.pyc\u001b[0m in \u001b[0;36mtrain_nn_augmented\u001b[1;34m(train_set_x, train_model, validate_model, test_model, n_train_batches, n_valid_batches, n_test_batches, n_epochs, output_len, decay_learning_rate_function, verbose, batch_size, flip_p, rotate_p, translate_p, noise_p)\u001b[0m\n\u001b[0;32m    538\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaussian_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Layers.pyc\u001b[0m in \u001b[0;36mrotate_image\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mim2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mdeepX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/anaconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.pyc\u001b[0m in \u001b[0;36mrotate\u001b[1;34m(input, angle, axes, reshape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m//=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m//=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mcoordinates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "batch_size = 50\n",
    "train_set_x = shared_x\n",
    "n_epochs = 100\n",
    "lrs = [.0005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano_Data.train_FSRCNN(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0.15, rotate_p=0.15)\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch_data_augment')\n",
    "\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch=50_data_augment',place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.0005******************************************\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (64, 3, 9, 9)\n",
      "image_shape...: (25, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (32, 64, 5, 5)\n",
      "image_shape...: (25, 64, 8, 8)\n",
      "input shape....: Shape.0\n",
      "decon layer....\n",
      "\n",
      "filter_shape...: (3, 32, 10, 10)\n",
      "image_shape...: (25, 32, 8, 8)\n",
      "input shape....: Shape.0\n",
      "epoch 1, minibatch 883/883, validation cost 3414.975586 mse/pixel: 3.938842 pnsr: 42.990822\n",
      "     epoch 1, minibatch 883/883, test cost of best model 3470.791992 perpixel mse 4.003220 and test pnsr 42.672157\n",
      "epoch 2, minibatch 883/883, validation cost 2099.389160 mse/pixel: 2.421441 pnsr: 45.021412\n",
      "     epoch 2, minibatch 883/883, test cost of best model 2200.888916 perpixel mse 2.538511 and test pnsr 44.628735\n",
      "epoch 3, minibatch 883/883, validation cost 1679.367920 mse/pixel: 1.936987 pnsr: 45.955887\n",
      "new learning rate:\n",
      "CudaNdarray(0.000500000023749)\n",
      "     epoch 3, minibatch 883/883, test cost of best model 1787.917114 perpixel mse 2.062188 and test pnsr 45.540981\n",
      "epoch 4, minibatch 883/883, validation cost 1431.303223 mse/pixel: 1.650869 pnsr: 46.636448\n",
      "new learning rate:\n",
      "CudaNdarray(0.000497500004712)\n",
      "     epoch 4, minibatch 883/883, test cost of best model 1489.536377 perpixel mse 1.718035 and test pnsr 46.335739\n",
      "epoch 5, minibatch 883/883, validation cost 1377.544067 mse/pixel: 1.588863 pnsr: 46.804405\n",
      "new learning rate:\n",
      "CudaNdarray(0.000495012500323)\n",
      "     epoch 5, minibatch 883/883, test cost of best model 1410.514893 perpixel mse 1.626891 and test pnsr 46.571354\n",
      "epoch 6, minibatch 883/883, validation cost 1357.542358 mse/pixel: 1.565793 pnsr: 46.879047\n",
      "new learning rate:\n",
      "CudaNdarray(0.000492537452374)\n",
      "     epoch 6, minibatch 883/883, test cost of best model 1393.423584 perpixel mse 1.607178 and test pnsr 46.622734\n",
      "epoch 7, minibatch 883/883, validation cost 1364.642212 mse/pixel: 1.573982 pnsr: 46.875511\n",
      "new learning rate:\n",
      "CudaNdarray(0.000490074744448)\n",
      "epoch 8, minibatch 883/883, validation cost 1498.759155 mse/pixel: 1.728673 pnsr: 46.521313\n",
      "new learning rate:\n",
      "CudaNdarray(0.000487624376547)\n",
      "epoch 9, minibatch 883/883, validation cost 1563.626709 mse/pixel: 1.803491 pnsr: 46.399731\n",
      "new learning rate:\n",
      "CudaNdarray(0.000485186261358)\n",
      "epoch 10, minibatch 883/883, validation cost 1453.432495 mse/pixel: 1.676393 pnsr: 46.705616\n",
      "new learning rate:\n",
      "CudaNdarray(0.000482760340674)\n",
      "epoch 11, minibatch 883/883, validation cost 1505.862671 mse/pixel: 1.736866 pnsr: 46.576672\n",
      "new learning rate:\n",
      "CudaNdarray(0.000480346527183)\n",
      "epoch 12, minibatch 883/883, validation cost 1649.482666 mse/pixel: 1.902517 pnsr: 46.218212\n",
      "new learning rate:\n",
      "CudaNdarray(0.000477944791783)\n",
      "epoch 13, minibatch 883/883, validation cost 1688.665894 mse/pixel: 1.947711 pnsr: 46.128956\n",
      "new learning rate:\n",
      "CudaNdarray(0.000475555076264)\n",
      "epoch 14, minibatch 883/883, validation cost 1729.458130 mse/pixel: 1.994761 pnsr: 46.019367\n",
      "new learning rate:\n",
      "CudaNdarray(0.000473177293316)\n",
      "epoch 15, minibatch 883/883, validation cost 1726.720703 mse/pixel: 1.991604 pnsr: 46.026653\n",
      "new learning rate:\n",
      "CudaNdarray(0.000470811413834)\n",
      "epoch 16, minibatch 883/883, validation cost 1684.693237 mse/pixel: 1.943129 pnsr: 46.116531\n",
      "new learning rate:\n",
      "CudaNdarray(0.000468457350507)\n",
      "epoch 17, minibatch 883/883, validation cost 1699.633423 mse/pixel: 1.960361 pnsr: 46.088913\n",
      "new learning rate:\n",
      "CudaNdarray(0.000466115074232)\n",
      "epoch 18, minibatch 883/883, validation cost 1646.776245 mse/pixel: 1.899396 pnsr: 46.204571\n",
      "new learning rate:\n",
      "CudaNdarray(0.000463784497697)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cf4e80e715ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                              \u001b[0mshared_test_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshared_test_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                              n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0.15, rotate_p=0.15)\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mreconstructed_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_valid_batches\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_valid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Theano_Data.pyc\u001b[0m in \u001b[0;36mtrain_FSRCNN\u001b[1;34m(train_set_x, train_set_y, valid_set_x, valid_set_y, test_set_x, test_set_y, n_train_batches, n_valid_batches, n_test_batches, n_epochs, batch_size, lr, upsampling_factor, flip_p, rotate_p, translate_p, noise_p)\u001b[0m\n\u001b[0;32m    252\u001b[0m     train_nn_augmented(train_set_x, train_model, validate_model, test_model,\n\u001b[0;32m    253\u001b[0m             \u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecay_learning_rate_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m              batch_size = batch_size, flip_p = flip_p, rotate_p = rotate_p, translate_p = translate_p, noise_p = noise_p)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/e4040_project_ahj1/FSRCNN_Layers.py\u001b[0m in \u001b[0;36mtrain_nn_augmented\u001b[1;34m(train_set_x, train_model, validate_model, test_model, n_train_batches, n_valid_batches, n_test_batches, n_epochs, output_len, decay_learning_rate_function, verbose, batch_size, flip_p, rotate_p, translate_p, noise_p)\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m             \u001b[0mcost_ij\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse_ij\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpnsr_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                 print('training @ iter = ' + str(iter) + \"\\tcost = \" + str(cost_ij) + \n",
      "\u001b[1;32m/mnt/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "batch_size = 25\n",
    "train_set_x = shared_x\n",
    "n_epochs = 100\n",
    "lrs = [.0005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano_Data.train_FSRCNN(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0.15, rotate_p=0.15)\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch_data_augment')\n",
    "\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch=50_data_augment',place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ****************************** lr = 0.0005******************************************\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (64, 3, 9, 9)\n",
      "image_shape...: (25, 3, 8, 8)\n",
      "input shape....: Shape.0\n",
      "lovely....\n",
      "\n",
      "filter_shape...: (32, 64, 5, 5)\n",
      "image_shape...: (25, 64, 8, 8)\n",
      "input shape....: Shape.0\n",
      "decon layer....\n",
      "\n",
      "filter_shape...: (3, 32, 10, 10)\n",
      "image_shape...: (25, 32, 8, 8)\n",
      "input shape....: Shape.0\n",
      "epoch 1, minibatch 883/883, validation cost 2707.576416 mse/pixel: 3.122926 pnsr: 43.904869\n",
      "     epoch 1, minibatch 883/883, test cost of best model 3281.938232 perpixel mse 3.785395 and test pnsr 43.175339\n",
      "epoch 2, minibatch 883/883, validation cost 1788.682739 mse/pixel: 2.063071 pnsr: 45.718666\n",
      "     epoch 2, minibatch 883/883, test cost of best model 2177.526611 perpixel mse 2.511565 and test pnsr 44.931870\n",
      "epoch 3, minibatch 883/883, validation cost 1317.822266 mse/pixel: 1.519980 pnsr: 47.041355\n",
      "new learning rate:\n",
      "CudaNdarray(0.000500000023749)\n",
      "     epoch 3, minibatch 883/883, test cost of best model 1540.157349 perpixel mse 1.776422 and test pnsr 46.435658\n",
      "epoch 4, minibatch 883/883, validation cost 1030.978882 mse/pixel: 1.189134 pnsr: 48.118942\n",
      "     epoch 4, minibatch 883/883, test cost of best model 1147.137451 perpixel mse 1.323111 and test pnsr 47.699928\n",
      "epoch 5, minibatch 883/883, validation cost 870.972839 mse/pixel: 1.004582 pnsr: 48.878365\n",
      "new learning rate:\n",
      "CudaNdarray(0.000497500004712)\n",
      "     epoch 5, minibatch 883/883, test cost of best model 957.599670 perpixel mse 1.104498 and test pnsr 48.488674\n",
      "epoch 6, minibatch 883/883, validation cost 788.412231 mse/pixel: 0.909357 pnsr: 49.323017\n",
      "new learning rate:\n",
      "CudaNdarray(0.000495012500323)\n",
      "     epoch 6, minibatch 883/883, test cost of best model 870.909546 perpixel mse 1.004509 and test pnsr 48.906738\n",
      "epoch 7, minibatch 883/883, validation cost 743.866394 mse/pixel: 0.857978 pnsr: 49.576172\n",
      "new learning rate:\n",
      "CudaNdarray(0.000492537452374)\n",
      "     epoch 7, minibatch 883/883, test cost of best model 813.283264 perpixel mse 0.938043 and test pnsr 49.202896\n",
      "epoch 8, minibatch 883/883, validation cost 705.273682 mse/pixel: 0.813464 pnsr: 49.840046\n",
      "new learning rate:\n",
      "CudaNdarray(0.000490074744448)\n",
      "     epoch 8, minibatch 883/883, test cost of best model 742.622253 perpixel mse 0.856542 and test pnsr 49.623943\n",
      "epoch 9, minibatch 883/883, validation cost 651.561340 mse/pixel: 0.751513 pnsr: 50.212944\n",
      "new learning rate:\n",
      "CudaNdarray(0.000487624376547)\n",
      "     epoch 9, minibatch 883/883, test cost of best model 686.956665 perpixel mse 0.792337 and test pnsr 50.015671\n",
      "epoch 10, minibatch 883/883, validation cost 632.385864 mse/pixel: 0.729396 pnsr: 50.364376\n",
      "new learning rate:\n",
      "CudaNdarray(0.000485186261358)\n",
      "     epoch 10, minibatch 883/883, test cost of best model 666.306030 perpixel mse 0.768519 and test pnsr 50.181576\n",
      "epoch 11, minibatch 883/883, validation cost 580.377441 mse/pixel: 0.669409 pnsr: 50.791313\n",
      "new learning rate:\n",
      "CudaNdarray(0.000482760340674)\n",
      "     epoch 11, minibatch 883/883, test cost of best model 612.402893 perpixel mse 0.706347 and test pnsr 50.601547\n",
      "epoch 12, minibatch 883/883, validation cost 558.174866 mse/pixel: 0.643800 pnsr: 50.942692\n",
      "new learning rate:\n",
      "CudaNdarray(0.000480346527183)\n",
      "     epoch 12, minibatch 883/883, test cost of best model 590.818176 perpixel mse 0.681451 and test pnsr 50.727261\n",
      "epoch 13, minibatch 883/883, validation cost 565.134705 mse/pixel: 0.651828 pnsr: 50.882195\n",
      "new learning rate:\n",
      "CudaNdarray(0.000477944791783)\n",
      "epoch 14, minibatch 883/883, validation cost 562.204102 mse/pixel: 0.648448 pnsr: 50.896061\n",
      "new learning rate:\n",
      "CudaNdarray(0.000475555076264)\n",
      "epoch 15, minibatch 883/883, validation cost 528.863403 mse/pixel: 0.609992 pnsr: 51.177738\n",
      "new learning rate:\n",
      "CudaNdarray(0.000473177293316)\n",
      "     epoch 15, minibatch 883/883, test cost of best model 550.775696 perpixel mse 0.635266 and test pnsr 50.976612\n",
      "epoch 16, minibatch 883/883, validation cost 537.835327 mse/pixel: 0.620341 pnsr: 51.106964\n",
      "new learning rate:\n",
      "CudaNdarray(0.000470811413834)\n",
      "epoch 17, minibatch 883/883, validation cost 505.534302 mse/pixel: 0.583085 pnsr: 51.402042\n",
      "new learning rate:\n",
      "CudaNdarray(0.000468457350507)\n",
      "     epoch 17, minibatch 883/883, test cost of best model 511.843384 perpixel mse 0.590361 and test pnsr 51.345428\n",
      "epoch 18, minibatch 883/883, validation cost 513.142151 mse/pixel: 0.591859 pnsr: 51.359005\n",
      "new learning rate:\n",
      "CudaNdarray(0.000466115074232)\n",
      "epoch 19, minibatch 883/883, validation cost 500.576111 mse/pixel: 0.577366 pnsr: 51.471542\n",
      "new learning rate:\n",
      "CudaNdarray(0.000463784497697)\n",
      "     epoch 19, minibatch 883/883, test cost of best model 496.768188 perpixel mse 0.572974 and test pnsr 51.488201\n",
      "epoch 20, minibatch 883/883, validation cost 497.439880 mse/pixel: 0.573748 pnsr: 51.529690\n",
      "new learning rate:\n",
      "CudaNdarray(0.000461465591798)\n",
      "     epoch 20, minibatch 883/883, test cost of best model 491.227112 perpixel mse 0.566583 and test pnsr 51.554771\n",
      "epoch 21, minibatch 883/883, validation cost 466.429688 mse/pixel: 0.537981 pnsr: 51.820278\n",
      "new learning rate:\n",
      "CudaNdarray(0.000459158269223)\n",
      "     epoch 21, minibatch 883/883, test cost of best model 467.008087 perpixel mse 0.538648 and test pnsr 51.800240\n",
      "epoch 22, minibatch 883/883, validation cost 492.338196 mse/pixel: 0.567864 pnsr: 51.580578\n",
      "new learning rate:\n",
      "CudaNdarray(0.000456862471765)\n",
      "epoch 23, minibatch 883/883, validation cost 466.327209 mse/pixel: 0.537863 pnsr: 51.841515\n",
      "new learning rate:\n",
      "CudaNdarray(0.00045457817032)\n",
      "     epoch 23, minibatch 883/883, test cost of best model 457.866272 perpixel mse 0.528104 and test pnsr 51.905270\n",
      "epoch 24, minibatch 883/883, validation cost 451.758392 mse/pixel: 0.521059 pnsr: 51.978043\n",
      "new learning rate:\n",
      "CudaNdarray(0.000452305277577)\n",
      "     epoch 24, minibatch 883/883, test cost of best model 446.020203 perpixel mse 0.514441 and test pnsr 52.017452\n",
      "epoch 25, minibatch 883/883, validation cost 443.251892 mse/pixel: 0.511248 pnsr: 52.071175\n",
      "new learning rate:\n",
      "CudaNdarray(0.000450043764431)\n",
      "     epoch 25, minibatch 883/883, test cost of best model 438.496246 perpixel mse 0.505763 and test pnsr 52.108963\n",
      "epoch 26, minibatch 883/883, validation cost 448.486847 mse/pixel: 0.517286 pnsr: 52.035984\n",
      "new learning rate:\n",
      "CudaNdarray(0.000447793543572)\n",
      "epoch 27, minibatch 883/883, validation cost 429.446350 mse/pixel: 0.495324 pnsr: 52.229862\n",
      "     epoch 27, minibatch 883/883, test cost of best model 417.835754 perpixel mse 0.481933 and test pnsr 52.356766\n",
      "epoch 28, minibatch 883/883, validation cost 444.025085 mse/pixel: 0.512140 pnsr: 52.106827\n",
      "epoch 29, minibatch 883/883, validation cost 465.048676 mse/pixel: 0.536388 pnsr: 51.890488\n",
      "new learning rate:\n",
      "CudaNdarray(0.000445554585895)\n",
      "epoch 30, minibatch 883/883, validation cost 428.721588 mse/pixel: 0.494489 pnsr: 52.266136\n",
      "     epoch 30, minibatch 883/883, test cost of best model 417.806244 perpixel mse 0.481899 and test pnsr 52.405304\n",
      "epoch 31, minibatch 883/883, validation cost 427.851318 mse/pixel: 0.493485 pnsr: 52.285381\n",
      "new learning rate:\n",
      "CudaNdarray(0.000443326804088)\n",
      "     epoch 31, minibatch 883/883, test cost of best model 414.725067 perpixel mse 0.478345 and test pnsr 52.458115\n",
      "epoch 32, minibatch 883/883, validation cost 438.945068 mse/pixel: 0.506280 pnsr: 52.170113\n",
      "epoch 33, minibatch 883/883, validation cost 429.258484 mse/pixel: 0.495108 pnsr: 52.296776\n",
      "epoch 34, minibatch 883/883, validation cost 425.680084 mse/pixel: 0.490981 pnsr: 52.322025\n",
      "new learning rate:\n",
      "CudaNdarray(0.000441110169049)\n",
      "     epoch 34, minibatch 883/883, test cost of best model 412.460846 perpixel mse 0.475733 and test pnsr 52.502193\n",
      "epoch 35, minibatch 883/883, validation cost 446.034119 mse/pixel: 0.514457 pnsr: 52.091106\n",
      "epoch 36, minibatch 883/883, validation cost 438.105164 mse/pixel: 0.505312 pnsr: 52.196541\n",
      "new learning rate:\n",
      "CudaNdarray(0.00043890462257)\n",
      "epoch 37, minibatch 883/883, validation cost 435.656006 mse/pixel: 0.502487 pnsr: 52.190224\n",
      "new learning rate:\n",
      "CudaNdarray(0.000436710106442)\n",
      "epoch 38, minibatch 883/883, validation cost 411.996674 mse/pixel: 0.475198 pnsr: 52.455292\n",
      "     epoch 38, minibatch 883/883, test cost of best model 400.197693 perpixel mse 0.461589 and test pnsr 52.630276\n",
      "epoch 39, minibatch 883/883, validation cost 459.867065 mse/pixel: 0.530412 pnsr: 51.959641\n",
      "epoch 40, minibatch 883/883, validation cost 406.464325 mse/pixel: 0.468817 pnsr: 52.526299\n",
      "     epoch 40, minibatch 883/883, test cost of best model 400.260468 perpixel mse 0.461661 and test pnsr 52.634701\n",
      "epoch 41, minibatch 883/883, validation cost 422.758881 mse/pixel: 0.487611 pnsr: 52.347687\n",
      "new learning rate:\n",
      "CudaNdarray(0.000434526562458)\n",
      "epoch 42, minibatch 883/883, validation cost 459.864136 mse/pixel: 0.530408 pnsr: 51.969234\n",
      "epoch 43, minibatch 883/883, validation cost 433.178253 mse/pixel: 0.499629 pnsr: 52.231331\n",
      "epoch 44, minibatch 883/883, validation cost 462.326996 mse/pixel: 0.533249 pnsr: 51.946621\n",
      "epoch 45, minibatch 883/883, validation cost 408.504028 mse/pixel: 0.471170 pnsr: 52.479504\n",
      "epoch 46, minibatch 883/883, validation cost 419.250793 mse/pixel: 0.483565 pnsr: 52.383354\n",
      "new learning rate:\n",
      "CudaNdarray(0.00043235393241)\n",
      "epoch 47, minibatch 883/883, validation cost 400.779541 mse/pixel: 0.462260 pnsr: 52.569069\n",
      "new learning rate:\n",
      "CudaNdarray(0.000430192158092)\n",
      "     epoch 47, minibatch 883/883, test cost of best model 386.116302 perpixel mse 0.445348 and test pnsr 52.804543\n",
      "epoch 48, minibatch 883/883, validation cost 450.938446 mse/pixel: 0.520114 pnsr: 52.056358\n",
      "epoch 49, minibatch 883/883, validation cost 426.195892 mse/pixel: 0.491575 pnsr: 52.305996\n",
      "epoch 50, minibatch 883/883, validation cost 396.225647 mse/pixel: 0.457008 pnsr: 52.657104\n",
      "new learning rate:\n",
      "CudaNdarray(0.000428041210398)\n",
      "     epoch 50, minibatch 883/883, test cost of best model 383.406250 perpixel mse 0.442222 and test pnsr 52.902626\n",
      "epoch 51, minibatch 883/883, validation cost 404.328796 mse/pixel: 0.466354 pnsr: 52.545094\n",
      "new learning rate:\n",
      "CudaNdarray(0.000425901002018)\n",
      "epoch 52, minibatch 883/883, validation cost 439.093719 mse/pixel: 0.506452 pnsr: 52.231541\n",
      "epoch 53, minibatch 883/883, validation cost 381.527252 mse/pixel: 0.440055 pnsr: 52.813976\n",
      "     epoch 53, minibatch 883/883, test cost of best model 371.239899 perpixel mse 0.428189 and test pnsr 53.031269\n",
      "epoch 54, minibatch 883/883, validation cost 432.158966 mse/pixel: 0.498453 pnsr: 52.248802\n",
      "new learning rate:\n",
      "CudaNdarray(0.000423771503847)\n",
      "epoch 55, minibatch 883/883, validation cost 431.112976 mse/pixel: 0.497247 pnsr: 52.276772\n",
      "new learning rate:\n",
      "CudaNdarray(0.000421652657678)\n",
      "epoch 56, minibatch 883/883, validation cost 405.754669 mse/pixel: 0.467998 pnsr: 52.520222\n",
      "new learning rate:\n",
      "CudaNdarray(0.000419544405304)\n",
      "epoch 57, minibatch 883/883, validation cost 424.768280 mse/pixel: 0.489929 pnsr: 52.319416\n",
      "new learning rate:\n",
      "CudaNdarray(0.000417446688516)\n",
      "epoch 58, minibatch 883/883, validation cost 446.202271 mse/pixel: 0.514651 pnsr: 52.098225\n",
      "epoch 59, minibatch 883/883, validation cost 419.057953 mse/pixel: 0.483343 pnsr: 52.372662\n",
      "epoch 60, minibatch 883/883, validation cost 438.355347 mse/pixel: 0.505600 pnsr: 52.194050\n",
      "epoch 61, minibatch 883/883, validation cost 421.578369 mse/pixel: 0.486250 pnsr: 52.379078\n",
      "epoch 62, minibatch 883/883, validation cost 423.494385 mse/pixel: 0.488459 pnsr: 52.359814\n",
      "new learning rate:\n",
      "CudaNdarray(0.000415359449107)\n",
      "epoch 63, minibatch 883/883, validation cost 404.646454 mse/pixel: 0.466720 pnsr: 52.567467\n",
      "new learning rate:\n",
      "CudaNdarray(0.000413282657973)\n",
      "epoch 64, minibatch 883/883, validation cost 432.522766 mse/pixel: 0.498873 pnsr: 52.266010\n",
      "new learning rate:\n",
      "CudaNdarray(0.000411216256907)\n",
      "epoch 65, minibatch 883/883, validation cost 419.329254 mse/pixel: 0.483655 pnsr: 52.414940\n",
      "new learning rate:\n",
      "CudaNdarray(0.000409160187701)\n",
      "epoch 66, minibatch 883/883, validation cost 395.436951 mse/pixel: 0.456098 pnsr: 52.657078\n",
      "new learning rate:\n",
      "CudaNdarray(0.000407114392146)\n",
      "epoch 67, minibatch 883/883, validation cost 421.635101 mse/pixel: 0.486315 pnsr: 52.413242\n",
      "new learning rate:\n",
      "CudaNdarray(0.000405078812037)\n",
      "epoch 68, minibatch 883/883, validation cost 398.594513 mse/pixel: 0.459740 pnsr: 52.645596\n",
      "new learning rate:\n",
      "CudaNdarray(0.000403053418268)\n",
      "epoch 69, minibatch 883/883, validation cost 398.980225 mse/pixel: 0.460185 pnsr: 52.649395\n",
      "new learning rate:\n",
      "CudaNdarray(0.000401038152631)\n",
      "epoch 70, minibatch 883/883, validation cost 413.544037 mse/pixel: 0.476983 pnsr: 52.454491\n",
      "new learning rate:\n",
      "CudaNdarray(0.000399032956921)\n",
      "epoch 71, minibatch 883/883, validation cost 422.363281 mse/pixel: 0.487155 pnsr: 52.376652\n",
      "new learning rate:\n",
      "CudaNdarray(0.000397037802031)\n",
      "epoch 72, minibatch 883/883, validation cost 452.492462 mse/pixel: 0.521906 pnsr: 52.070526\n",
      "epoch 73, minibatch 883/883, validation cost 406.921478 mse/pixel: 0.469344 pnsr: 52.542496\n",
      "epoch 74, minibatch 883/883, validation cost 438.820282 mse/pixel: 0.506136 pnsr: 52.215092\n",
      "epoch 75, minibatch 883/883, validation cost 420.158417 mse/pixel: 0.484612 pnsr: 52.423794\n",
      "epoch 76, minibatch 883/883, validation cost 423.069336 mse/pixel: 0.487969 pnsr: 52.354084\n",
      "new learning rate:\n",
      "CudaNdarray(0.000395052600652)\n",
      "epoch 77, minibatch 883/883, validation cost 447.951508 mse/pixel: 0.516668 pnsr: 52.106499\n",
      "epoch 78, minibatch 883/883, validation cost 416.823792 mse/pixel: 0.480766 pnsr: 52.438694\n",
      "epoch 79, minibatch 883/883, validation cost 430.132172 mse/pixel: 0.496116 pnsr: 52.294849\n",
      "new learning rate:\n",
      "CudaNdarray(0.000393077352783)\n",
      "epoch 80, minibatch 883/883, validation cost 427.863922 mse/pixel: 0.493499 pnsr: 52.327282\n",
      "new learning rate:\n",
      "CudaNdarray(0.000391111971112)\n",
      "epoch 81, minibatch 883/883, validation cost 426.517273 mse/pixel: 0.491946 pnsr: 52.349670\n",
      "new learning rate:\n",
      "CudaNdarray(0.000389156426536)\n",
      "epoch 82, minibatch 883/883, validation cost 437.565033 mse/pixel: 0.504689 pnsr: 52.226761\n",
      "epoch 83, minibatch 883/883, validation cost 393.239410 mse/pixel: 0.453563 pnsr: 52.717178\n",
      "epoch 84, minibatch 883/883, validation cost 407.031555 mse/pixel: 0.469471 pnsr: 52.571503\n",
      "new learning rate:\n",
      "CudaNdarray(0.000387210631743)\n",
      "epoch 85, minibatch 883/883, validation cost 432.434235 mse/pixel: 0.498771 pnsr: 52.275043\n",
      "new learning rate:\n",
      "CudaNdarray(0.000385274586733)\n",
      "epoch 86, minibatch 883/883, validation cost 414.272461 mse/pixel: 0.477823 pnsr: 52.492764\n",
      "new learning rate:\n",
      "CudaNdarray(0.000383348204195)\n",
      "epoch 87, minibatch 883/883, validation cost 417.754395 mse/pixel: 0.481839 pnsr: 52.429619\n",
      "new learning rate:\n",
      "CudaNdarray(0.000381431455025)\n",
      "epoch 88, minibatch 883/883, validation cost 399.762115 mse/pixel: 0.461087 pnsr: 52.676365\n",
      "new learning rate:\n",
      "CudaNdarray(0.000379524310119)\n",
      "epoch 89, minibatch 883/883, validation cost 441.030609 mse/pixel: 0.508686 pnsr: 52.198196\n",
      "epoch 90, minibatch 883/883, validation cost 398.071259 mse/pixel: 0.459136 pnsr: 52.659702\n",
      "epoch 91, minibatch 883/883, validation cost 427.638031 mse/pixel: 0.493239 pnsr: 52.368984\n",
      "new learning rate:\n",
      "CudaNdarray(0.000377626682166)\n",
      "epoch 92, minibatch 883/883, validation cost 415.559143 mse/pixel: 0.479307 pnsr: 52.517811\n",
      "new learning rate:\n",
      "CudaNdarray(0.000375738542061)\n",
      "epoch 93, minibatch 883/883, validation cost 413.757690 mse/pixel: 0.477229 pnsr: 52.498810\n",
      "new learning rate:\n",
      "CudaNdarray(0.000373859860701)\n",
      "epoch 94, minibatch 883/883, validation cost 437.421448 mse/pixel: 0.504523 pnsr: 52.234314\n",
      "epoch 95, minibatch 883/883, validation cost 430.005615 mse/pixel: 0.495970 pnsr: 52.347065\n",
      "epoch 96, minibatch 883/883, validation cost 438.908936 mse/pixel: 0.506239 pnsr: 52.219501\n",
      "epoch 97, minibatch 883/883, validation cost 429.855377 mse/pixel: 0.495796 pnsr: 52.323322\n",
      "epoch 98, minibatch 883/883, validation cost 431.981842 mse/pixel: 0.498249 pnsr: 52.298199\n",
      "new learning rate:\n",
      "CudaNdarray(0.000371990550775)\n",
      "epoch 99, minibatch 883/883, validation cost 447.046051 mse/pixel: 0.515624 pnsr: 52.142910\n",
      "epoch 100, minibatch 883/883, validation cost 399.953156 mse/pixel: 0.461307 pnsr: 52.630882\n",
      "Optimization complete.\n",
      "Best validation pnsr of 381.527252 obtained at iteration 46799, with test cost 371.239899 perpixel mse 0.428189 test pnsr 53.031269\n",
      "The training process for function train_FSRCNN ran for 51.16m\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 288, '\\n')\n",
      "(19, 19, '\\n')\n",
      "(256, 256, '\\n')\n",
      "(16, 16, '\\n')\n",
      "(280, 280, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(344, 228, '\\n')\n",
      "(23, 14, '\\n')\n",
      "(480, 500, '\\n')\n",
      "(32, 34, '\\n')\n",
      "(576, 720, '\\n')\n",
      "(39, 50, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(361, 250, '\\n')\n",
      "(24, 16, '\\n')\n",
      "(276, 276, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(362, 500, '\\n')\n",
      "(24, 34, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 768, '\\n')\n",
      "(35, 53, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(656, 529, '\\n')\n",
      "(45, 36, '\\n')\n",
      "(391, 586, '\\n')\n",
      "(26, 40, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 288, '\\n')\n",
      "(19, 19, '\\n')\n",
      "(256, 256, '\\n')\n",
      "(16, 16, '\\n')\n",
      "(280, 280, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(344, 228, '\\n')\n",
      "(23, 14, '\\n')\n",
      "(480, 500, '\\n')\n",
      "(32, 34, '\\n')\n",
      "(576, 720, '\\n')\n",
      "(39, 50, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(361, 250, '\\n')\n",
      "(24, 16, '\\n')\n",
      "(276, 276, '\\n')\n",
      "(18, 18, '\\n')\n",
      "(362, 500, '\\n')\n",
      "(24, 34, '\\n')\n",
      "(288, 352, '\\n')\n",
      "(19, 23, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(512, 768, '\\n')\n",
      "(35, 53, '\\n')\n",
      "(512, 512, '\\n')\n",
      "(35, 35, '\\n')\n",
      "(656, 529, '\\n')\n",
      "(45, 36, '\\n')\n",
      "(391, 586, '\\n')\n",
      "(26, 40, '\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.py:516: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "batch_size = 25\n",
    "train_set_x = shared_x\n",
    "n_epochs = 100\n",
    "lrs = [.0005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano_Data.train_FSRCNN(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0, rotate_p=0)\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch_data_augment')\n",
    "\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch=50_data_augment',place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 194072868 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b095496b9960>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m shared_test_y = theano.shared(np.asarray(test_y,\n\u001b[0;32m     17\u001b[0m                                        dtype=theano.config.floatX),\n\u001b[1;32m---> 18\u001b[1;33m                          borrow=True)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtrain_set_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/anaconda2/lib/python2.7/site-packages/theano/compile/sharedvalue.pyc\u001b[0m in \u001b[0;36mshared\u001b[1;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[1;32m--> 247\u001b[1;33m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/var.pyc\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[1;34m(value, name, strict, allow_downcast, borrow, broadcastable, target)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# function requires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mdeviceval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ('Error allocating 194072868 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")"
     ]
    }
   ],
   "source": [
    "shared_x = theano.shared(np.asarray(upsampled_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_y = theano.shared(np.asarray(data_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_x = theano.shared(np.asarray(up_val_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_val_y = theano.shared(np.asarray(valid_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_x = theano.shared(np.asarray(up_test_x,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "shared_test_y = theano.shared(np.asarray(test_y,\n",
    "                                       dtype=theano.config.floatX),\n",
    "                         borrow=True)\n",
    "batch_size = 50\n",
    "train_set_x = shared_x\n",
    "n_epochs = 50\n",
    "lrs = [.0005]\n",
    "for lr in lrs:\n",
    "    print \"\\n\\n ****************************** lr = \" + str(lr) +\"******************************************\"\n",
    "    learning_rate = lr\n",
    "\n",
    "    n_train_batches = upsampled_x.shape[0]/batch_size\n",
    "    n_valid_batches = up_val_x.shape[0]/batch_size\n",
    "    n_test_batches = up_test_x.shape[0]/batch_size\n",
    "\n",
    "\n",
    "\n",
    "    val_model,test_model = FSRCNN_Theano_Data.train_FSRCNN(shared_x,shared_y,\n",
    "                             shared_val_x,shared_val_y,\n",
    "                             shared_test_x,shared_test_y,\n",
    "                            n_train_batches, n_valid_batches, n_test_batches, \n",
    "                             n_epochs, batch_size,learning_rate,upsampling_factor=4, flip_p=0.5, translate_p=0.35, rotate_p=0)\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment_translate')\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch_data_augment_translate')\n",
    "\n",
    "reconstructed_imgs = np.zeros(((n_valid_batches+1)*batch_size, 3, 17, 17))\n",
    "for i in xrange(n_valid_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = val_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Validation_Subsamples_RGB_4/',patch_dim=17,dataset='validate_lr=5e4_batch=50_data_augment_translate', place=True)\n",
    "reconstructed_imgs = np.zeros((14851, 3, 17, 17))\n",
    "for i in xrange(n_test_batches):\n",
    "     cost,MSE_per_pixel,psnr,reconstucted_patches = test_model(i)\n",
    "     reconstructed_imgs[i*batch_size:(i+1)*batch_size,:,:,:] = reconstucted_patches\n",
    "\n",
    "FSRCNN_Theano.rebuild_images(reconstructed_imgs,'/home/ubuntu/Data/Test_Subsamples_RGB_4/',patch_dim=17,dataset='test_lr=5e4_batch=50_data_augment_translate',place=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
